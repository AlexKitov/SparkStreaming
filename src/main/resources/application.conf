default {
  spark {
    master="local[*]"
    app.name="SparkStreaming"
    poll.interval=20
    log.level="ERROR"
  }
  hdfs {
    path {
      base="hdfs://localhost:9000/"
      data="data/"
      stream1="stream1/"
      stream2="stream2/"
      stream3="stream3/"
      poulationStream="city-country/"
      fail="fail/"
      warehouse="warehouse/"
      storage="temperatures/"
      temperature="temperature.parquet"
      dashboard="dashboard.parquet"
      dataStream1=${default.hdfs.path.base}${default.hdfs.path.data}${default.hdfs.path.stream1}
      dataStream2=${default.hdfs.path.base}${default.hdfs.path.data}${default.hdfs.path.stream2}
      dataStream3=${default.hdfs.path.base}${default.hdfs.path.data}${default.hdfs.path.stream3}
      failPath=${default.hdfs.path.base}${default.hdfs.path.fail}
      populationStream=${default.hdfs.path.base}${default.hdfs.path.data}${default.hdfs.path.poulationStream}
      dashboardPath=${default.hdfs.path.warehousePath}${default.hdfs.path.storage}${default.hdfs.path.dashboard}
      warehousePath=${default.hdfs.path.base}${default.hdfs.path.warehouse}
      temperaturePath=${default.hdfs.path.warehousePath}${default.hdfs.path.storage}${default.hdfs.path.temperature}
      checkpointLocation=${default.hdfs.path.base}checkpoint/temperature
      fileNameDateFormat="yyyyMMddHHmmss_SSS"
    }
  }
  xml {
    skip.pattern="<?xml"
    in.date.format="yyyy-MM-dd'T'HH:mm:ss"
  }
  out {
    date.format="YYYY-MM-dd"
    expireAfterMillis=60000
  }
}

dev {}
